## 通过执行时间判断算法的优劣
在日常开发中，当实现一个算法之后，通常我们会进行基准测试用以验证程序的执行效率，即算法的优劣性。抛开golang提供的基准测试功能，实际上我们可以通过
`time`包提供的`Since()`方法获取程序从开始到执行结束的时间，如此便可以测试在不同输入下程序的执行时间，绘制成图标后可以直观的反应出算法的优劣性。

## 通过执行时间判断算法优劣的局限性
1. 当基于上述方法对比两个算法的优劣时，必须将两个算法都实现，然后再通过测试对比执行时间得到结果。  
2. 程序的执行时间不单单与算法有关，同时与机器的性能有关。因此，这种方法很难对比出两个算法的优劣！除非在硬件环境、软件环境、输入等等都相同
的情况下。  
3. 输入数据是人为构造的，人力很难穷尽所有的数据情况用于测试，而且也不现实。所以，通过测试执行时间得到的结果很难反映一个算法的全部能力。  

## 理想的分析算法效率的方法
通过了解用执行时间推断算法效率的方法，我们更希望有一种方法能够：  
1. 摆脱硬件环境、软件环境等限制，可以任意评价两个算法的相对效率  
2. 能够考虑所有输入  
3. 不需要将算法都实现就可以推断出算法的效率  

幸运的是已经有大佬开发出来了这种方法：`大O表示法`，相信大家都见过。那它是怎么来的呢？下边将一步一步的分析。

## 原子操作
我们定义一系列原子操作用于评估算法的执行时间：  
1. 赋值
2. 取值
3. 算数运算
4. 调用函数（不包括函数内的操作执行）
5. 函数返回
6. 通过索引访问数组元素

此处的原子操作不同于并发概念中的原子操作，这里的原子操作从时间角度去考虑：我们认为每一个原子操作对应一条或者多条机器指令，其执行时间是固定的。
因此，每一个原子操作的执行时间我们是不关心的，我们关心的是某种算法的实现执行了多少个原子操作，执行的原子操作数量与算法的真实执行时间是成正比的。

## 引入数学函数
我们已经知道：
1. 原子操作的执行时间是常数，因此原子操作的执行数量就可以代表算法的真实执行时间。
2. 算法研究的是执行时间与输入之间的关系
所以，我们就可以将原子操作数与输入的关系描述成数学函数：f(n)，n代表输入大小。

## 最坏输入研究
一个算法执行效率的评估，最理想的肯定是研究算法的平均执行时间。不幸的是，这要求我们要找到 最好输入情况 和 最坏输入情况，之后才能找到平均值，
这个工作是很复杂的。因此在算法分析中，我们一般考虑的是最坏情况输入，上述函数f(n)中的n代表的就是最坏情况输入。

## NEXT
[数学函数](../b_数学函数)
